import streamlit as st
from langchain_core.messages import AIMessage, HumanMessage
from src.agent import app as devmanual_ai_app


def extract_text_from_message(message):
    """Gemini ì‘ë‹µì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.

    Gemini 2.5/3 ëª¨ë¸ì€ contentë¥¼ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ë°˜í™˜í•˜ë¯€ë¡œ,
    ì´ë¥¼ ì˜¬ë°”ë¥´ê²Œ ì²˜ë¦¬í•˜ì—¬ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œí•©ë‹ˆë‹¤.
    """
    # Gemini 3+ ëª¨ë¸ì€ .text ì†ì„± ì œê³µ
    if hasattr(message, 'text') and message.text:
        return message.text

    # contentê°€ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° (Gemini 2.5/3)
    if isinstance(message.content, list):
        text_parts = []
        for block in message.content:
            if isinstance(block, dict) and 'text' in block:
                text_parts.append(block['text'])
            elif isinstance(block, str):
                text_parts.append(block)
        return '\n'.join(text_parts)

    # ì¼ë°˜ ë¬¸ìì—´
    return message.content


# --- í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(
    page_title="DevManual-AI",
    page_icon="ğŸ¤–"
)
st.title("ğŸ‘¨â€ğŸ’» DevManual-AI")
st.caption("RAGì™€ LangGraph ê¸°ë°˜ì˜ ê¸°ìˆ  ë¬¸ì„œ ë¶„ì„ ë° ì½”ë“œ ìƒì„± AI ì—ì´ì „íŠ¸")

# --- ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” ---
if "messages" not in st.session_state:    
    st.session_state.messages = [
        AIMessage(content="ì•ˆë…•í•˜ì„¸ìš”! DevManual-AIì…ë‹ˆë‹¤. ê¸°ìˆ  ë¬¸ì„œ, ì½”ë“œ ìƒì„±, ì›¹ ê²€ìƒ‰ ë“± ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”. ì œê°€ ê°€ì§„ ë„êµ¬ë“¤ì„ ì‚¬ìš©í•´ ìµœì ì˜ ë‹µë³€ì„ ì°¾ì•„ ë“œë¦´ê²Œìš”.")
    ]

# ì´ì „ ëŒ€í™” ë‚´ìš© í‘œì‹œ
for message in st.session_state.messages:
    # langchainì˜ AIMessage, HumanMessage ê°ì²´ì˜ role ì†ì„±ì„ í™•ì¸í•©ë‹ˆë‹¤.
    if isinstance(message, AIMessage):
        with st.chat_message("assistant"):
            st.markdown(extract_text_from_message(message))
    elif isinstance(message, HumanMessage):
        with st.chat_message("user"):
            st.markdown(message.content)

if prompt := st.chat_input("ê¶ê¸ˆí•œ ê¸°ìˆ ì´ë‚˜ ì½”ë“œì— ëŒ€í•´ ì§ˆë¬¸í•´ë³´ì„¸ìš”!"):
    # 1. ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€í•˜ê³  í™”ë©´ì— í‘œì‹œ
    st.session_state.messages.append(HumanMessage(content=prompt))
    with st.chat_message("user"):
        st.markdown(prompt)

    # 2. AI ì‘ë‹µ ìƒì„± ë° í‘œì‹œ
    with st.chat_message("assistant"):
        with st.spinner("AIê°€ ì—¬ëŸ¬ ë„êµ¬ë¥¼ ì‚¬ìš©í•´ ìƒê° ì¤‘ì…ë‹ˆë‹¤..."):
            # ìŠˆí¼ë°”ì´ì € ì—ì´ì „íŠ¸ëŠ” ì „ì²´ ëŒ€í™” ê¸°ë¡ì„ ì…ë ¥ìœ¼ë¡œ ë°›ìŠµë‹ˆë‹¤.
            inputs = {"messages": st.session_state.messages}
            
            # ì•ˆì •ì„±ì„ ìœ„í•´ .invoke()ë¥¼ ì‚¬ìš©í•´ ìµœì¢… ê²°ê³¼ë§Œ í•œë²ˆì— ë°›ìŠµë‹ˆë‹¤.
            response = devmanual_ai_app.invoke(inputs)
            
            # ìŠˆí¼ë°”ì´ì €ì˜ ìµœì¢… ë‹µë³€ì€ ì‘ë‹µì˜ 'messages' ë¦¬ìŠ¤íŠ¸ì˜ ë§ˆì§€ë§‰ì— ìˆìŠµë‹ˆë‹¤.
            final_answer = response['messages'][-1]

            # ìµœì¢… ë‹µë³€ì„ í™”ë©´ì— ì¶œë ¥í•©ë‹ˆë‹¤. (Gemini 2.5/3 í˜•ì‹ ì²˜ë¦¬)
            st.markdown(extract_text_from_message(final_answer))

    # 3. AI ë©”ì‹œì§€ë¥¼ ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€
    # final_answerëŠ” BaseMessage ê°ì²´ì´ë¯€ë¡œ ê·¸ëŒ€ë¡œ ì¶”ê°€í•©ë‹ˆë‹¤.
    st.session_state.messages.append(final_answer)